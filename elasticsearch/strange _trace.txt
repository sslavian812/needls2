"C:\Program Files\Java\jdk1.8.0_20\bin\java" -DstartId=1 -Dcount=10 -Didea.launcher.port=7533 "-Didea.launcher.bin.path=C:\Program Files (x86)\JetBrains\IntelliJ IDEA 14.0.2\bin" -Dfile.encoding=UTF-8 -classpath "C:\Program Files\Java\jdk1.8.0_20\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\rt.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_20\jre\lib\ext\zipfs.jar;C:\Dropbox\yandex\needls2\target\classes;C:\Program Files (x86)\scala\lib\scala-actors-migration.jar;C:\Program Files (x86)\scala\lib\scala-actors.jar;C:\Program Files (x86)\scala\lib\scala-library.jar;C:\Program Files (x86)\scala\lib\scala-reflect.jar;C:\Program Files (x86)\scala\lib\scala-swing.jar;C:\Users\viacheslav\.m2\repository\org\scala-lang\scala-library\2.10.4\scala-library-2.10.4.jar;C:\Users\viacheslav\.m2\repository\org\apache\spark\spark-core_2.10\1.1.1\spark-core_2.10-1.1.1.jar;C:\Users\viacheslav\.m2\repository\org\apache\hadoop\hadoop-client\1.0.4\hadoop-client-1.0.4.jar;C:\Users\viacheslav\.m2\repository\org\apache\hadoop\hadoop-core\1.0.4\hadoop-core-1.0.4.jar;C:\Users\viacheslav\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\viacheslav\.m2\repository\hsqldb\hsqldb\1.8.0.10\hsqldb-1.8.0.10.jar;C:\Users\viacheslav\.m2\repository\oro\oro\2.0.8\oro-2.0.8.jar;C:\Users\viacheslav\.m2\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;C:\Users\viacheslav\.m2\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;C:\Users\viacheslav\.m2\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;C:\Users\viacheslav\.m2\repository\org\apache\curator\curator-client\2.4.0\curator-client-2.4.0.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-plus\8.1.14.v20131031\jetty-plus-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\orbit\javax.transaction\1.1.1.v201105210645\javax.transaction-1.1.1.v201105210645.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-webapp\8.1.14.v20131031\jetty-webapp-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-xml\8.1.14.v20131031\jetty-xml-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-servlet\8.1.14.v20131031\jetty-servlet-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-jndi\8.1.14.v20131031\jetty-jndi-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\orbit\javax.mail.glassfish\1.4.1.v201005082020\javax.mail.glassfish-1.4.1.v201005082020.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\orbit\javax.activation\1.1.0.v201105071233\javax.activation-1.1.0.v201105071233.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-security\8.1.14.v20131031\jetty-security-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-util\8.1.14.v20131031\jetty-util-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-server\8.1.14.v20131031\jetty-server-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\orbit\javax.servlet\3.0.0.v201112011016\javax.servlet-3.0.0.v201112011016.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-continuation\8.1.14.v20131031\jetty-continuation-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-http\8.1.14.v20131031\jetty-http-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\org\eclipse\jetty\jetty-io\8.1.14.v20131031\jetty-io-8.1.14.v20131031.jar;C:\Users\viacheslav\.m2\repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;C:\Users\viacheslav\.m2\repository\org\apache\commons\commons-lang3\3.3.2\commons-lang3-3.3.2.jar;C:\Users\viacheslav\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\viacheslav\.m2\repository\org\slf4j\slf4j-api\1.7.5\slf4j-api-1.7.5.jar;C:\Users\viacheslav\.m2\repository\org\slf4j\jul-to-slf4j\1.7.5\jul-to-slf4j-1.7.5.jar;C:\Users\viacheslav\.m2\repository\org\slf4j\jcl-over-slf4j\1.7.5\jcl-over-slf4j-1.7.5.jar;C:\Users\viacheslav\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\viacheslav\.m2\repository\org\slf4j\slf4j-log4j12\1.7.5\slf4j-log4j12-1.7.5.jar;C:\Users\viacheslav\.m2\repository\com\ning\compress-lzf\1.0.0\compress-lzf-1.0.0.jar;C:\Users\viacheslav\.m2\repository\org\xerial\snappy\snappy-java\1.0.5.3\snappy-java-1.0.5.3.jar;C:\Users\viacheslav\.m2\repository\net\jpountz\lz4\lz4\1.2.0\lz4-1.2.0.jar;C:\Users\viacheslav\.m2\repository\com\twitter\chill_2.10\0.3.6\chill_2.10-0.3.6.jar;C:\Users\viacheslav\.m2\repository\com\esotericsoftware\kryo\kryo\2.21\kryo-2.21.jar;C:\Users\viacheslav\.m2\repository\com\esotericsoftware\reflectasm\reflectasm\1.07\reflectasm-1.07-shaded.jar;C:\Users\viacheslav\.m2\repository\com\esotericsoftware\minlog\minlog\1.2\minlog-1.2.jar;C:\Users\viacheslav\.m2\repository\org\objenesis\objenesis\1.2\objenesis-1.2.jar;C:\Users\viacheslav\.m2\repository\com\twitter\chill-java\0.3.6\chill-java-0.3.6.jar;C:\Users\viacheslav\.m2\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;C:\Users\viacheslav\.m2\repository\org\spark-project\akka\akka-remote_2.10\2.2.3-shaded-protobuf\akka-remote_2.10-2.2.3-shaded-protobuf.jar;C:\Users\viacheslav\.m2\repository\org\spark-project\akka\akka-actor_2.10\2.2.3-shaded-protobuf\akka-actor_2.10-2.2.3-shaded-protobuf.jar;C:\Users\viacheslav\.m2\repository\com\typesafe\config\1.0.2\config-1.0.2.jar;C:\Users\viacheslav\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\viacheslav\.m2\repository\org\spark-project\protobuf\protobuf-java\2.4.1-shaded\protobuf-java-2.4.1-shaded.jar;C:\Users\viacheslav\.m2\repository\org\uncommons\maths\uncommons-maths\1.2.2a\uncommons-maths-1.2.2a.jar;C:\Users\viacheslav\.m2\repository\org\spark-project\akka\akka-slf4j_2.10\2.2.3-shaded-protobuf\akka-slf4j_2.10-2.2.3-shaded-protobuf.jar;C:\Users\viacheslav\.m2\repository\colt\colt\1.2.0\colt-1.2.0.jar;C:\Users\viacheslav\.m2\repository\concurrent\concurrent\1.3.4\concurrent-1.3.4.jar;C:\Users\viacheslav\.m2\repository\org\apache\mesos\mesos\0.18.1\mesos-0.18.1-shaded-protobuf.jar;C:\Users\viacheslav\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\viacheslav\.m2\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;C:\Users\viacheslav\.m2\repository\com\codahale\metrics\metrics-core\3.0.0\metrics-core-3.0.0.jar;C:\Users\viacheslav\.m2\repository\com\codahale\metrics\metrics-jvm\3.0.0\metrics-jvm-3.0.0.jar;C:\Users\viacheslav\.m2\repository\com\codahale\metrics\metrics-json\3.0.0\metrics-json-3.0.0.jar;C:\Users\viacheslav\.m2\repository\com\codahale\metrics\metrics-graphite\3.0.0\metrics-graphite-3.0.0.jar;C:\Users\viacheslav\.m2\repository\org\tachyonproject\tachyon-client\0.5.0\tachyon-client-0.5.0.jar;C:\Users\viacheslav\.m2\repository\org\tachyonproject\tachyon\0.5.0\tachyon-0.5.0.jar;C:\Users\viacheslav\.m2\repository\org\spark-project\pyrolite\2.0.1\pyrolite-2.0.1.jar;C:\Users\viacheslav\.m2\repository\net\sf\py4j\py4j\0.8.2.1\py4j-0.8.2.1.jar;C:\Users\viacheslav\.m2\repository\org\apache\spark\spark-bagel_2.10\1.1.1\spark-bagel_2.10-1.1.1.jar;C:\Users\viacheslav\.m2\repository\org\apache\spark\spark-mllib_2.10\1.1.1\spark-mllib_2.10-1.1.1.jar;C:\Users\viacheslav\.m2\repository\org\scalanlp\breeze_2.10\0.9\breeze_2.10-0.9.jar;C:\Users\viacheslav\.m2\repository\org\scalanlp\breeze-macros_2.10\0.3.1\breeze-macros_2.10-0.3.1.jar;C:\Users\viacheslav\.m2\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;C:\Users\viacheslav\.m2\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;C:\Users\viacheslav\.m2\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;C:\Users\viacheslav\.m2\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;C:\Users\viacheslav\.m2\repository\org\spire-math\spire_2.10\0.7.4\spire_2.10-0.7.4.jar;C:\Users\viacheslav\.m2\repository\org\spire-math\spire-macros_2.10\0.7.4\spire-macros_2.10-0.7.4.jar;C:\Users\viacheslav\.m2\repository\org\apache\spark\spark-repl_2.10\1.1.1\spark-repl_2.10-1.1.1.jar;C:\Users\viacheslav\.m2\repository\org\scala-lang\scala-compiler\2.10.4\scala-compiler-2.10.4.jar;C:\Users\viacheslav\.m2\repository\org\scala-lang\scala-reflect\2.10.4\scala-reflect-2.10.4.jar;C:\Users\viacheslav\.m2\repository\org\scala-lang\jline\2.10.4\jline-2.10.4.jar;C:\Users\viacheslav\.m2\repository\org\fusesource\jansi\jansi\1.4\jansi-1.4.jar;C:\Users\viacheslav\.m2\repository\org\apache\spark\spark-streaming_2.10\1.1.1\spark-streaming_2.10-1.1.1.jar;C:\Users\viacheslav\.m2\repository\org\apache\spark\spark-sql_2.10\1.1.1\spark-sql_2.10-1.1.1.jar;C:\Users\viacheslav\.m2\repository\org\apache\spark\spark-catalyst_2.10\1.1.1\spark-catalyst_2.10-1.1.1.jar;C:\Users\viacheslav\.m2\repository\org\scalamacros\quasiquotes_2.10\2.0.1\quasiquotes_2.10-2.0.1.jar;C:\Users\viacheslav\.m2\repository\com\twitter\parquet-column\1.4.3\parquet-column-1.4.3.jar;C:\Users\viacheslav\.m2\repository\com\twitter\parquet-common\1.4.3\parquet-common-1.4.3.jar;C:\Users\viacheslav\.m2\repository\com\twitter\parquet-encoding\1.4.3\parquet-encoding-1.4.3.jar;C:\Users\viacheslav\.m2\repository\com\twitter\parquet-generator\1.4.3\parquet-generator-1.4.3.jar;C:\Users\viacheslav\.m2\repository\com\twitter\parquet-hadoop\1.4.3\parquet-hadoop-1.4.3.jar;C:\Users\viacheslav\.m2\repository\com\twitter\parquet-format\2.0.0\parquet-format-2.0.0.jar;C:\Users\viacheslav\.m2\repository\com\twitter\parquet-jackson\1.4.3\parquet-jackson-1.4.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\spark\spark-graphx_2.10\1.1.1\spark-graphx_2.10-1.1.1.jar;C:\Users\viacheslav\.m2\repository\org\jblas\jblas\1.2.3\jblas-1.2.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\hadoop\hadoop-common\2.4.0\hadoop-common-2.4.0.jar;C:\Users\viacheslav\.m2\repository\org\apache\hadoop\hadoop-annotations\2.4.0\hadoop-annotations-2.4.0.jar;C:\Program Files\Java\jdk1.8.0_20\lib\tools.jar;C:\Users\viacheslav\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\viacheslav\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\viacheslav\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\viacheslav\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\viacheslav\.m2\repository\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;C:\Users\viacheslav\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\viacheslav\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\viacheslav\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\viacheslav\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\viacheslav\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\viacheslav\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\viacheslav\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\viacheslav\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\viacheslav\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\viacheslav\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\viacheslav\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\viacheslav\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\viacheslav\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.3\jackson-jaxrs-1.8.3.jar;C:\Users\viacheslav\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\viacheslav\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\viacheslav\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\viacheslav\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\viacheslav\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\viacheslav\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\viacheslav\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\viacheslav\.m2\repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;C:\Users\viacheslav\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\viacheslav\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\viacheslav\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\viacheslav\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\viacheslav\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\viacheslav\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\viacheslav\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\viacheslav\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\viacheslav\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\viacheslav\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\viacheslav\.m2\repository\org\apache\hadoop\hadoop-auth\2.4.0\hadoop-auth-2.4.0.jar;C:\Users\viacheslav\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\viacheslav\.m2\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;C:\Users\viacheslav\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\viacheslav\.m2\repository\org\apache\zookeeper\zookeeper\3.4.5\zookeeper-3.4.5.jar;C:\Users\viacheslav\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\viacheslav\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\viacheslav\.m2\repository\org\elasticsearch\elasticsearch\1.4.4\elasticsearch-1.4.4.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-core\4.10.3\lucene-core-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-analyzers-common\4.10.3\lucene-analyzers-common-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-queries\4.10.3\lucene-queries-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-memory\4.10.3\lucene-memory-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-highlighter\4.10.3\lucene-highlighter-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-queryparser\4.10.3\lucene-queryparser-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-sandbox\4.10.3\lucene-sandbox-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-suggest\4.10.3\lucene-suggest-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-misc\4.10.3\lucene-misc-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-join\4.10.3\lucene-join-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-grouping\4.10.3\lucene-grouping-4.10.3.jar;C:\Users\viacheslav\.m2\repository\org\apache\lucene\lucene-spatial\4.10.3\lucene-spatial-4.10.3.jar;C:\Users\viacheslav\.m2\repository\com\spatial4j\spatial4j\0.4.1\spatial4j-0.4.1.jar;C:\Users\viacheslav\.m2\repository\org\antlr\antlr-runtime\3.5\antlr-runtime-3.5.jar;C:\Users\viacheslav\.m2\repository\org\ow2\asm\asm\4.1\asm-4.1.jar;C:\Users\viacheslav\.m2\repository\org\ow2\asm\asm-commons\4.1\asm-commons-4.1.jar;C:\Users\viacheslav\.m2\repository\org\json4s\json4s-jackson_2.10\3.2.11\json4s-jackson_2.10-3.2.11.jar;C:\Users\viacheslav\.m2\repository\org\json4s\json4s-core_2.10\3.2.11\json4s-core_2.10-3.2.11.jar;C:\Users\viacheslav\.m2\repository\org\json4s\json4s-ast_2.10\3.2.11\json4s-ast_2.10-3.2.11.jar;C:\Users\viacheslav\.m2\repository\org\scala-lang\scalap\2.10.0\scalap-2.10.0.jar;C:\Users\viacheslav\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.3.1\jackson-databind-2.3.1.jar;C:\Users\viacheslav\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.3.0\jackson-annotations-2.3.0.jar;C:\Users\viacheslav\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.3.1\jackson-core-2.3.1.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 14.0.2\lib\idea_rt.jar" com.intellij.rt.execution.application.AppMain ru.yandex.spark.UsersCollecting
15/04/18 16:24:50 INFO spark.SecurityManager: Changing view acls to: viacheslav
15/04/18 16:24:50 INFO spark.SecurityManager: Changing modify acls to: viacheslav
15/04/18 16:24:50 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(viacheslav); users with modify permissions: Set(viacheslav)
15/04/18 16:24:50 INFO slf4j.Slf4jLogger: Slf4jLogger started
15/04/18 16:24:51 INFO Remoting: Starting remoting
15/04/18 16:24:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@viacheslavPC.Dlink:48198]
15/04/18 16:24:51 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@viacheslavPC.Dlink:48198]
15/04/18 16:24:51 INFO util.Utils: Successfully started service 'sparkDriver' on port 48198.
15/04/18 16:24:51 INFO spark.SparkEnv: Registering MapOutputTracker
15/04/18 16:24:51 INFO spark.SparkEnv: Registering BlockManagerMaster
15/04/18 16:24:51 INFO storage.DiskBlockManager: Created local directory at C:\Users\VIACHE~1\AppData\Local\Temp\spark-local-20150418162451-d64e
15/04/18 16:24:51 INFO util.Utils: Successfully started service 'Connection manager for block manager' on port 48201.
15/04/18 16:24:51 INFO network.ConnectionManager: Bound socket to port 48201 with id = ConnectionManagerId(viacheslavPC.Dlink,48201)
15/04/18 16:24:51 INFO storage.MemoryStore: MemoryStore started with capacity 969.8 MB
15/04/18 16:24:51 INFO storage.BlockManagerMaster: Trying to register BlockManager
15/04/18 16:24:51 INFO storage.BlockManagerMasterActor: Registering block manager viacheslavPC.Dlink:48201 with 969.8 MB RAM, BlockManagerId(<driver>, viacheslavPC.Dlink, 48201, 0)
15/04/18 16:24:51 INFO storage.BlockManagerMaster: Registered BlockManager
15/04/18 16:24:51 INFO spark.HttpFileServer: HTTP File server directory is C:\Users\VIACHE~1\AppData\Local\Temp\spark-795c4524-a93e-4813-8f83-5a61c384becc
15/04/18 16:24:51 INFO spark.HttpServer: Starting HTTP Server
15/04/18 16:24:51 INFO server.Server: jetty-8.1.14.v20131031
15/04/18 16:24:51 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48202
15/04/18 16:24:51 INFO util.Utils: Successfully started service 'HTTP file server' on port 48202.
15/04/18 16:24:52 INFO server.Server: jetty-8.1.14.v20131031
15/04/18 16:24:52 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:195)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1504)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1495)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:205)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:234)
	at ru.yandex.spark.Spark$.<init>(Spark.scala:36)
	at ru.yandex.spark.Spark$.<clinit>(Spark.scala)
	at ru.yandex.spark.UsersCollecting$.main(UsersCollecting.scala:34)
	at ru.yandex.spark.UsersCollecting.main(UsersCollecting.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
15/04/18 16:24:52 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@5af3a0f: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:195)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1504)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1495)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:205)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:234)
	at ru.yandex.spark.Spark$.<init>(Spark.scala:36)
	at ru.yandex.spark.Spark$.<clinit>(Spark.scala)
	at ru.yandex.spark.UsersCollecting$.main(UsersCollecting.scala:34)
	at ru.yandex.spark.UsersCollecting.main(UsersCollecting.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/04/18 16:24:52 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/04/18 16:24:52 INFO server.Server: jetty-8.1.14.v20131031
15/04/18 16:24:52 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:195)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1504)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1495)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:205)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:234)
	at ru.yandex.spark.Spark$.<init>(Spark.scala:36)
	at ru.yandex.spark.Spark$.<clinit>(Spark.scala)
	at ru.yandex.spark.UsersCollecting$.main(UsersCollecting.scala:34)
	at ru.yandex.spark.UsersCollecting.main(UsersCollecting.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
15/04/18 16:24:52 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@7a791b66: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:195)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1504)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1495)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:205)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:234)
	at ru.yandex.spark.Spark$.<init>(Spark.scala:36)
	at ru.yandex.spark.Spark$.<clinit>(Spark.scala)
	at ru.yandex.spark.UsersCollecting$.main(UsersCollecting.scala:34)
	at ru.yandex.spark.UsersCollecting.main(UsersCollecting.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/04/18 16:24:52 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/04/18 16:24:52 INFO server.Server: jetty-8.1.14.v20131031
15/04/18 16:24:52 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:195)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1504)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1495)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:205)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:234)
	at ru.yandex.spark.Spark$.<init>(Spark.scala:36)
	at ru.yandex.spark.Spark$.<clinit>(Spark.scala)
	at ru.yandex.spark.UsersCollecting$.main(UsersCollecting.scala:34)
	at ru.yandex.spark.UsersCollecting.main(UsersCollecting.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
15/04/18 16:24:52 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@207ea13: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:195)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.ui.JettyUtils$$anonfun$4.apply(JettyUtils.scala:205)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1504)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1495)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:205)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:234)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:234)
	at ru.yandex.spark.Spark$.<init>(Spark.scala:36)
	at ru.yandex.spark.Spark$.<clinit>(Spark.scala)
	at ru.yandex.spark.UsersCollecting$.main(UsersCollecting.scala:34)
	at ru.yandex.spark.UsersCollecting.main(UsersCollecting.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/04/18 16:24:52 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/04/18 16:24:52 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/04/18 16:24:52 INFO server.Server: jetty-8.1.14.v20131031
15/04/18 16:24:52 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4043
15/04/18 16:24:52 INFO util.Utils: Successfully started service 'SparkUI' on port 4043.
15/04/18 16:24:52 INFO ui.SparkUI: Started SparkUI at http://viacheslavPC.Dlink:4043
15/04/18 16:24:52 INFO util.AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@viacheslavPC.Dlink:48198/user/HeartbeatReceiver
15/04/18 16:24:53 INFO elasticsearch.node: [Wicked] version[1.4.4], pid[19196], build[c88f77f/2015-02-19T13:05:36Z]
15/04/18 16:24:53 INFO elasticsearch.node: [Wicked] initializing ...
15/04/18 16:24:53 INFO elasticsearch.plugins: [Wicked] loaded [], sites []
15/04/18 16:24:55 INFO elasticsearch.node: [Wicked] initialized
15/04/18 16:24:55 INFO elasticsearch.node: [Wicked] starting ...
15/04/18 16:24:55 INFO elasticsearch.transport: [Wicked] bound_address {inet[/0:0:0:0:0:0:0:0:9304]}, publish_address {inet[/192.168.0.89:9304]}
15/04/18 16:24:56 INFO elasticsearch.discovery: [Wicked] elasticsearch/5U2dPow_TqyP0TT05882ig
15/04/18 16:24:59 INFO cluster.service: [Wicked] detected_master [Bloodlust II][vsn6UFJLSu61ouOHw1h2wA][viacheslavPC][inet[/192.168.0.89:9302]], added {[Kismet][NMLkuDALSgC7-0ppDY13DQ][viacheslavPC][inet[/192.168.0.89:9300]],[Andreas von Strucker][TE9l9OfPRg-UhoCgMKQZUQ][viacheslavPC][inet[/192.168.0.89:9303]],[Hellcat][IVSubFSeTI-48ANWmMdk7g][viacheslavPC][inet[/192.168.0.89:9301]],[Bloodlust II][vsn6UFJLSu61ouOHw1h2wA][viacheslavPC][inet[/192.168.0.89:9302]],}, reason: zen-disco-receive(from master [[Bloodlust II][vsn6UFJLSu61ouOHw1h2wA][viacheslavPC][inet[/192.168.0.89:9302]]])
15/04/18 16:24:59 INFO elasticsearch.http: [Wicked] bound_address {inet[/0:0:0:0:0:0:0:0:9204]}, publish_address {inet[/192.168.0.89:9204]}
15/04/18 16:24:59 INFO elasticsearch.node: [Wicked] started
=======0-th iteration
15/04/18 16:24:59 INFO spark.SparkContext: Starting job: count at UsersCollecting.scala:43
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Got job 0 (count at UsersCollecting.scala:43) with 1 output partitions (allowLocal=false)
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Final stage: Stage 0(count at UsersCollecting.scala:43)
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Parents of final stage: List()
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Missing parents: List()
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Submitting Stage 0 (ParallelCollectionRDD[0] at parallelize at UsersCollecting.scala:34), which has no missing parents
15/04/18 16:24:59 INFO storage.MemoryStore: ensureFreeSpace(1056) called with curMem=0, maxMem=1016950947
15/04/18 16:24:59 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1056.0 B, free 969.8 MB)
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (ParallelCollectionRDD[0] at parallelize at UsersCollecting.scala:34)
15/04/18 16:24:59 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
15/04/18 16:24:59 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1199 bytes)
15/04/18 16:24:59 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
15/04/18 16:24:59 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 623 bytes result sent to driver
15/04/18 16:24:59 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 49 ms on localhost (1/1)
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Stage 0 (count at UsersCollecting.scala:43) finished in 0,066 s
15/04/18 16:24:59 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
MLQ.size = 0
15/04/18 16:24:59 INFO spark.SparkContext: Job finished: count at UsersCollecting.scala:43, took 0.205970779 s
15/04/18 16:24:59 INFO spark.SparkContext: Starting job: count at UsersCollecting.scala:50
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Registering RDD 7 (distinct at UsersCollecting.scala:49)
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Got job 1 (count at UsersCollecting.scala:50) with 1 output partitions (allowLocal=false)
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Final stage: Stage 1(count at UsersCollecting.scala:50)
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 2)
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Missing parents: List(Stage 2)
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[7] at distinct at UsersCollecting.scala:49), which has no missing parents
15/04/18 16:24:59 INFO storage.MemoryStore: ensureFreeSpace(3176) called with curMem=1056, maxMem=1016950947
15/04/18 16:24:59 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 969.8 MB)
15/04/18 16:24:59 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[7] at distinct at UsersCollecting.scala:49)
15/04/18 16:24:59 INFO scheduler.TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
15/04/18 16:24:59 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1, localhost, PROCESS_LOCAL, 1192 bytes)
15/04/18 16:24:59 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 1)
Downloading user 1
15/04/18 16:25:01 INFO storage.BlockManager: Removing broadcast 0
15/04/18 16:25:01 INFO storage.BlockManager: Removing block broadcast_0
15/04/18 16:25:01 INFO storage.MemoryStore: Block broadcast_0 of size 1056 dropped from memory (free 1016947771)
15/04/18 16:25:01 INFO spark.ContextCleaner: Cleaned broadcast 0
15/04/18 16:25:04 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 1). 814 bytes result sent to driver
15/04/18 16:25:04 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 4222 ms on localhost (1/1)
15/04/18 16:25:04 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Stage 2 (distinct at UsersCollecting.scala:49) finished in 4,223 s
15/04/18 16:25:04 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/04/18 16:25:04 INFO scheduler.DAGScheduler: running: Set()
15/04/18 16:25:04 INFO scheduler.DAGScheduler: waiting: Set(Stage 1)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: failed: Set()
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Missing parents for Stage 1: List()
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[9] at distinct at UsersCollecting.scala:49), which is now runnable
15/04/18 16:25:04 INFO storage.MemoryStore: ensureFreeSpace(2536) called with curMem=3176, maxMem=1016950947
15/04/18 16:25:04 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.5 KB, free 969.8 MB)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[9] at distinct at UsersCollecting.scala:49)
15/04/18 16:25:04 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
15/04/18 16:25:04 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 993 bytes)
15/04/18 16:25:04 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 2)
15/04/18 16:25:04 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:04 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:04 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 5 ms
friends.size = 716
15/04/18 16:25:04 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 2). 864 bytes result sent to driver
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Stage 1 (count at UsersCollecting.scala:50) finished in 0,073 s
15/04/18 16:25:04 INFO spark.SparkContext: Job finished: count at UsersCollecting.scala:50, took 4.338758347 s
15/04/18 16:25:04 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 73 ms on localhost (1/1)
15/04/18 16:25:04 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/04/18 16:25:04 INFO spark.SparkContext: Starting job: count at UsersCollecting.scala:53
15/04/18 16:25:04 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 141 bytes
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Registering RDD 11 (subtract at UsersCollecting.scala:52)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Registering RDD 12 (subtract at UsersCollecting.scala:52)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Got job 2 (count at UsersCollecting.scala:53) with 1 output partitions (allowLocal=false)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Final stage: Stage 3(count at UsersCollecting.scala:53)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 5, Stage 6)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Missing parents: List(Stage 5, Stage 6)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[11] at subtract at UsersCollecting.scala:52), which has no missing parents
15/04/18 16:25:04 INFO storage.MemoryStore: ensureFreeSpace(2744) called with curMem=5712, maxMem=1016950947
15/04/18 16:25:04 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 2.7 KB, free 969.8 MB)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[11] at subtract at UsersCollecting.scala:52)
15/04/18 16:25:04 INFO scheduler.TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
15/04/18 16:25:04 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3, localhost, PROCESS_LOCAL, 982 bytes)
15/04/18 16:25:04 INFO executor.Executor: Running task 0.0 in stage 5.0 (TID 3)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[12] at subtract at UsersCollecting.scala:52), which has no missing parents
15/04/18 16:25:04 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:04 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:04 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:25:04 INFO storage.MemoryStore: ensureFreeSpace(3296) called with curMem=8456, maxMem=1016950947
15/04/18 16:25:04 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.2 KB, free 969.8 MB)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from Stage 6 (MappedRDD[12] at subtract at UsersCollecting.scala:52)
15/04/18 16:25:04 INFO scheduler.TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
15/04/18 16:25:04 INFO executor.Executor: Finished task 0.0 in stage 5.0 (TID 3). 1005 bytes result sent to driver
15/04/18 16:25:04 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4, localhost, PROCESS_LOCAL, 1297 bytes)
15/04/18 16:25:04 INFO executor.Executor: Running task 0.0 in stage 6.0 (TID 4)
15/04/18 16:25:04 INFO executor.Executor: Finished task 0.0 in stage 6.0 (TID 4). 814 bytes result sent to driver
15/04/18 16:25:04 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 1301 bytes)
15/04/18 16:25:04 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 18 ms on localhost (1/2)
15/04/18 16:25:04 INFO executor.Executor: Running task 1.0 in stage 6.0 (TID 5)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Stage 5 (subtract at UsersCollecting.scala:52) finished in 0,095 s
15/04/18 16:25:04 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/04/18 16:25:04 INFO scheduler.DAGScheduler: running: Set(Stage 6)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: waiting: Set(Stage 3)
15/04/18 16:25:04 INFO scheduler.DAGScheduler: failed: Set()
Downloading user 1
15/04/18 16:25:04 INFO scheduler.DAGScheduler: Missing parents for Stage 3: List(Stage 6)
15/04/18 16:25:04 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 92 ms on localhost (1/1)
15/04/18 16:25:04 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
15/04/18 16:25:05 INFO executor.Executor: Finished task 1.0 in stage 6.0 (TID 5). 814 bytes result sent to driver
15/04/18 16:25:05 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 5) in 1622 ms on localhost (2/2)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Stage 6 (subtract at UsersCollecting.scala:52) finished in 1,685 s
15/04/18 16:25:05 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
15/04/18 16:25:05 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/04/18 16:25:05 INFO scheduler.DAGScheduler: running: Set()
15/04/18 16:25:05 INFO scheduler.DAGScheduler: waiting: Set(Stage 3)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: failed: Set()
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Missing parents for Stage 3: List()
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[14] at subtract at UsersCollecting.scala:52), which is now runnable
15/04/18 16:25:05 INFO storage.MemoryStore: ensureFreeSpace(2208) called with curMem=11752, maxMem=1016950947
15/04/18 16:25:05 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.2 KB, free 969.8 MB)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[14] at subtract at UsersCollecting.scala:52)
15/04/18 16:25:05 INFO scheduler.TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
15/04/18 16:25:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, PROCESS_LOCAL, 1839 bytes)
15/04/18 16:25:05 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 6)
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 2 blocks
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:25:05 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 6). 864 bytes result sent to driver
15/04/18 16:25:05 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 18 ms on localhost (1/1)
15/04/18 16:25:05 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Stage 3 (count at UsersCollecting.scala:53) finished in 0,019 s
MLQ.size = 716
15/04/18 16:25:05 INFO spark.SparkContext: Job finished: count at UsersCollecting.scala:53, took 1.745477664 s
15/04/18 16:25:05 INFO spark.SparkContext: Starting job: take at UsersCollecting.scala:55
15/04/18 16:25:05 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 141 bytes
15/04/18 16:25:05 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 141 bytes
15/04/18 16:25:05 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 151 bytes
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Got job 3 (take at UsersCollecting.scala:55) with 1 output partitions (allowLocal=true)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Final stage: Stage 7(take at UsersCollecting.scala:55)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 9, Stage 10)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Missing parents: List()
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[14] at subtract at UsersCollecting.scala:52), which has no missing parents
15/04/18 16:25:05 INFO storage.MemoryStore: ensureFreeSpace(2232) called with curMem=13960, maxMem=1016950947
15/04/18 16:25:05 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.2 KB, free 969.8 MB)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[14] at subtract at UsersCollecting.scala:52)
15/04/18 16:25:05 INFO scheduler.TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
15/04/18 16:25:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, PROCESS_LOCAL, 1839 bytes)
15/04/18 16:25:05 INFO executor.Executor: Running task 0.0 in stage 7.0 (TID 7)
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 2 blocks
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:25:05 INFO executor.Executor: Finished task 0.0 in stage 7.0 (TID 7). 918 bytes result sent to driver
15/04/18 16:25:05 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on localhost (1/1)
15/04/18 16:25:05 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Stage 7 (take at UsersCollecting.scala:55) finished in 0,009 s
15/04/18 16:25:05 INFO spark.SparkContext: Job finished: take at UsersCollecting.scala:55, took 0.020080499 s
15/04/18 16:25:05 INFO spark.SparkContext: Starting job: count at UsersCollecting.scala:56
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Got job 4 (count at UsersCollecting.scala:56) with 1 output partitions (allowLocal=false)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Final stage: Stage 11(count at UsersCollecting.scala:56)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Parents of final stage: List()
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Missing parents: List()
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Submitting Stage 11 (ParallelCollectionRDD[15] at parallelize at UsersCollecting.scala:55), which has no missing parents
15/04/18 16:25:05 INFO storage.MemoryStore: ensureFreeSpace(1056) called with curMem=16192, maxMem=1016950947
15/04/18 16:25:05 INFO storage.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1056.0 B, free 969.8 MB)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 11 (ParallelCollectionRDD[15] at parallelize at UsersCollecting.scala:55)
15/04/18 16:25:05 INFO scheduler.TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
15/04/18 16:25:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 8, localhost, PROCESS_LOCAL, 1291 bytes)
15/04/18 16:25:05 INFO executor.Executor: Running task 0.0 in stage 11.0 (TID 8)
15/04/18 16:25:05 INFO executor.Executor: Finished task 0.0 in stage 11.0 (TID 8). 623 bytes result sent to driver
15/04/18 16:25:05 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 8) in 4 ms on localhost (1/1)
15/04/18 16:25:05 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Stage 11 (count at UsersCollecting.scala:56) finished in 0,007 s
15/04/18 16:25:05 INFO spark.SparkContext: Job finished: count at UsersCollecting.scala:56, took 0.0134095 s
LOI.size = 10
15/04/18 16:25:05 INFO spark.SparkContext: Starting job: count at UsersCollecting.scala:59
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Registering RDD 16 (subtract at UsersCollecting.scala:58)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Registering RDD 17 (subtract at UsersCollecting.scala:58)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Got job 5 (count at UsersCollecting.scala:59) with 1 output partitions (allowLocal=false)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Final stage: Stage 12(count at UsersCollecting.scala:59)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 16, Stage 17)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Missing parents: List(Stage 16, Stage 17)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Submitting Stage 16 (MappedRDD[16] at subtract at UsersCollecting.scala:58), which has no missing parents
15/04/18 16:25:05 INFO storage.MemoryStore: ensureFreeSpace(2240) called with curMem=17248, maxMem=1016950947
15/04/18 16:25:05 INFO storage.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 2.2 KB, free 969.8 MB)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 16 (MappedRDD[16] at subtract at UsersCollecting.scala:58)
15/04/18 16:25:05 INFO scheduler.TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
15/04/18 16:25:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 9, localhost, PROCESS_LOCAL, 1828 bytes)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Submitting Stage 17 (MappedRDD[17] at subtract at UsersCollecting.scala:58), which has no missing parents
15/04/18 16:25:05 INFO executor.Executor: Running task 0.0 in stage 16.0 (TID 9)
15/04/18 16:25:05 INFO storage.MemoryStore: ensureFreeSpace(2048) called with curMem=19488, maxMem=1016950947
15/04/18 16:25:05 INFO storage.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 2.0 KB, free 969.8 MB)
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 17 (MappedRDD[17] at subtract at UsersCollecting.scala:58)
15/04/18 16:25:05 INFO scheduler.TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 2 blocks
15/04/18 16:25:05 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:25:05 INFO executor.Executor: Finished task 0.0 in stage 16.0 (TID 9). 1005 bytes result sent to driver
15/04/18 16:25:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 10, localhost, PROCESS_LOCAL, 1280 bytes)
15/04/18 16:25:05 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 9) in 21 ms on localhost (1/1)
15/04/18 16:25:05 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
15/04/18 16:25:05 INFO executor.Executor: Running task 0.0 in stage 17.0 (TID 10)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Stage 16 (subtract at UsersCollecting.scala:58) finished in 0,022 s
15/04/18 16:25:05 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/04/18 16:25:05 INFO scheduler.DAGScheduler: running: Set(Stage 17)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: waiting: Set(Stage 12)
15/04/18 16:25:05 INFO scheduler.DAGScheduler: failed: Set()
15/04/18 16:25:05 INFO scheduler.DAGScheduler: Missing parents for Stage 12: List(Stage 17)
15/04/18 16:25:06 INFO executor.Executor: Finished task 0.0 in stage 17.0 (TID 10). 814 bytes result sent to driver
15/04/18 16:25:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 10) in 12 ms on localhost (1/1)
15/04/18 16:25:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Stage 17 (subtract at UsersCollecting.scala:58) finished in 0,025 s
15/04/18 16:25:06 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/04/18 16:25:06 INFO scheduler.DAGScheduler: running: Set()
15/04/18 16:25:06 INFO scheduler.DAGScheduler: waiting: Set(Stage 12)
15/04/18 16:25:06 INFO scheduler.DAGScheduler: failed: Set()
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Missing parents for Stage 12: List()
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Submitting Stage 12 (MappedRDD[19] at subtract at UsersCollecting.scala:58), which is now runnable
15/04/18 16:25:06 INFO storage.MemoryStore: ensureFreeSpace(2208) called with curMem=21536, maxMem=1016950947
15/04/18 16:25:06 INFO storage.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 2.2 KB, free 969.8 MB)
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 12 (MappedRDD[19] at subtract at UsersCollecting.scala:58)
15/04/18 16:25:06 INFO scheduler.TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
15/04/18 16:25:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11, localhost, PROCESS_LOCAL, 1839 bytes)
15/04/18 16:25:06 INFO executor.Executor: Running task 0.0 in stage 12.0 (TID 11)
15/04/18 16:25:06 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:06 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:06 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:25:06 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:06 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:06 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
MLQ.size = 706
15/04/18 16:25:06 INFO executor.Executor: Finished task 0.0 in stage 12.0 (TID 11). 864 bytes result sent to driver
15/04/18 16:25:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 8 ms on localhost (1/1)
15/04/18 16:25:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Stage 12 (count at UsersCollecting.scala:59) finished in 0,009 s
15/04/18 16:25:06 INFO spark.SparkContext: Job finished: count at UsersCollecting.scala:59, took 0.057794793 s
15/04/18 16:25:06 INFO spark.SparkContext: Starting job: foreach at UsersCollecting.scala:63
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Got job 6 (foreach at UsersCollecting.scala:63) with 1 output partitions (allowLocal=false)
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Final stage: Stage 18(foreach at UsersCollecting.scala:63)
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Parents of final stage: List()
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Missing parents: List()
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Submitting Stage 18 (MappedRDD[3] at map at UsersCollecting.scala:45), which has no missing parents
15/04/18 16:25:06 INFO storage.MemoryStore: ensureFreeSpace(2088) called with curMem=23744, maxMem=1016950947
15/04/18 16:25:06 INFO storage.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 2.0 KB, free 969.8 MB)
Downloading user 1
15/04/18 16:25:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 18 (MappedRDD[3] at map at UsersCollecting.scala:45)
15/04/18 16:25:06 INFO scheduler.TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
15/04/18 16:25:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 12, localhost, PROCESS_LOCAL, 1203 bytes)
15/04/18 16:25:06 INFO executor.Executor: Running task 0.0 in stage 18.0 (TID 12)
Indexing user: 1
15/04/18 16:25:08 INFO executor.Executor: Finished task 0.0 in stage 18.0 (TID 12). 826 bytes result sent to driver
1 more users added to index
=======1-th iteration
15/04/18 16:25:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 12) in 2867 ms on localhost (1/1)
15/04/18 16:25:08 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Stage 18 (foreach at UsersCollecting.scala:63) finished in 2,870 s
15/04/18 16:25:08 INFO spark.SparkContext: Job finished: foreach at UsersCollecting.scala:63, took 2.878194177 s
15/04/18 16:25:08 INFO spark.SparkContext: Starting job: count at UsersCollecting.scala:43
15/04/18 16:25:08 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 141 bytes
15/04/18 16:25:08 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 151 bytes
15/04/18 16:25:08 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 141 bytes
15/04/18 16:25:08 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 141 bytes
15/04/18 16:25:08 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 141 bytes
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Got job 7 (count at UsersCollecting.scala:43) with 1 output partitions (allowLocal=false)
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Final stage: Stage 19(count at UsersCollecting.scala:43)
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 24, Stage 23)
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Missing parents: List()
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Submitting Stage 19 (MappedRDD[19] at subtract at UsersCollecting.scala:58), which has no missing parents
15/04/18 16:25:08 INFO storage.MemoryStore: ensureFreeSpace(2208) called with curMem=25832, maxMem=1016950947
15/04/18 16:25:08 INFO storage.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.2 KB, free 969.8 MB)
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 19 (MappedRDD[19] at subtract at UsersCollecting.scala:58)
15/04/18 16:25:08 INFO scheduler.TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
15/04/18 16:25:08 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 13, localhost, PROCESS_LOCAL, 1839 bytes)
15/04/18 16:25:08 INFO executor.Executor: Running task 0.0 in stage 19.0 (TID 13)
15/04/18 16:25:08 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:08 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:08 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:25:08 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:08 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:08 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/04/18 16:25:08 INFO executor.Executor: Finished task 0.0 in stage 19.0 (TID 13). 864 bytes result sent to driver
15/04/18 16:25:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 13) in 14 ms on localhost (1/1)
15/04/18 16:25:08 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Stage 19 (count at UsersCollecting.scala:43) finished in 0,016 s
MLQ.size = 706
15/04/18 16:25:08 INFO spark.SparkContext: Job finished: count at UsersCollecting.scala:43, took 0.044824262 s
15/04/18 16:25:08 INFO spark.SparkContext: Starting job: count at UsersCollecting.scala:50
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Registering RDD 24 (distinct at UsersCollecting.scala:49)
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Got job 8 (count at UsersCollecting.scala:50) with 1 output partitions (allowLocal=false)
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Final stage: Stage 25(count at UsersCollecting.scala:50)
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 26)
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Missing parents: List(Stage 26)
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Submitting Stage 26 (MappedRDD[24] at distinct at UsersCollecting.scala:49), which has no missing parents
15/04/18 16:25:08 INFO storage.MemoryStore: ensureFreeSpace(3176) called with curMem=28040, maxMem=1016950947
15/04/18 16:25:08 INFO storage.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.1 KB, free 969.8 MB)
15/04/18 16:25:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 26 (MappedRDD[24] at distinct at UsersCollecting.scala:49)
15/04/18 16:25:08 INFO scheduler.TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
15/04/18 16:25:08 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 14, localhost, PROCESS_LOCAL, 1280 bytes)
15/04/18 16:25:08 INFO executor.Executor: Running task 0.0 in stage 26.0 (TID 14)
Downloading user 907
Downloading user 20720185
Downloading user 29825869
Downloading user 1666872
Downloading user 294029
Downloading user 1708231
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 11
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_11
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_11 of size 2088 dropped from memory (free 1016921819)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 11
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 10
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_10
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_10 of size 2208 dropped from memory (free 1016924027)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 10
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 9
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_9
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_9 of size 2048 dropped from memory (free 1016926075)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 9
Downloading user 961430
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 8
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_8
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_8 of size 2240 dropped from memory (free 1016928315)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 8
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 7
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_7
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_7 of size 1056 dropped from memory (free 1016929371)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 7
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 6
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_6
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_6 of size 2232 dropped from memory (free 1016931603)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 6
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 5
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_5
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_5 of size 2208 dropped from memory (free 1016933811)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 5
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 4
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_4
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_4 of size 3296 dropped from memory (free 1016937107)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 4
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 3
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_3
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_3 of size 2744 dropped from memory (free 1016939851)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 3
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 2
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_2
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_2 of size 2536 dropped from memory (free 1016942387)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 2
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 1
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_1
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_1 of size 3176 dropped from memory (free 1016945563)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 1
15/04/18 16:25:30 INFO storage.BlockManager: Removing broadcast 12
15/04/18 16:25:30 INFO storage.BlockManager: Removing block broadcast_12
15/04/18 16:25:30 INFO storage.MemoryStore: Block broadcast_12 of size 2208 dropped from memory (free 1016947771)
15/04/18 16:25:30 INFO spark.ContextCleaner: Cleaned broadcast 12
Downloading user 2791
Downloading user 1824209
Downloading user 407032
15/04/18 16:25:44 INFO executor.Executor: Finished task 0.0 in stage 26.0 (TID 14). 1005 bytes result sent to driver
15/04/18 16:25:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 14) in 35101 ms on localhost (1/1)
15/04/18 16:25:44 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Stage 26 (distinct at UsersCollecting.scala:49) finished in 35,102 s
15/04/18 16:25:44 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/04/18 16:25:44 INFO scheduler.DAGScheduler: running: Set()
15/04/18 16:25:44 INFO scheduler.DAGScheduler: waiting: Set(Stage 25)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: failed: Set()
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Missing parents for Stage 25: List()
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Submitting Stage 25 (MappedRDD[26] at distinct at UsersCollecting.scala:49), which is now runnable
15/04/18 16:25:44 INFO storage.MemoryStore: ensureFreeSpace(2536) called with curMem=3176, maxMem=1016950947
15/04/18 16:25:44 INFO storage.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 2.5 KB, free 969.8 MB)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 25 (MappedRDD[26] at distinct at UsersCollecting.scala:49)
15/04/18 16:25:44 INFO scheduler.TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
15/04/18 16:25:44 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 25.0 (TID 15, localhost, PROCESS_LOCAL, 993 bytes)
15/04/18 16:25:44 INFO executor.Executor: Running task 0.0 in stage 25.0 (TID 15)
15/04/18 16:25:44 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:44 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:44 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:25:44 INFO executor.Executor: Finished task 0.0 in stage 25.0 (TID 15). 864 bytes result sent to driver
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Stage 25 (count at UsersCollecting.scala:50) finished in 0,049 s
15/04/18 16:25:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 25.0 (TID 15) in 48 ms on localhost (1/1)
15/04/18 16:25:44 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
15/04/18 16:25:44 INFO spark.SparkContext: Job finished: count at UsersCollecting.scala:50, took 35.165720566 s
friends.size = 7695
15/04/18 16:25:44 INFO spark.SparkContext: Starting job: count at UsersCollecting.scala:53
15/04/18 16:25:44 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 141 bytes
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Registering RDD 28 (subtract at UsersCollecting.scala:52)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Registering RDD 29 (subtract at UsersCollecting.scala:52)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Got job 9 (count at UsersCollecting.scala:53) with 1 output partitions (allowLocal=false)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Final stage: Stage 27(count at UsersCollecting.scala:53)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 30, Stage 29)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Missing parents: List(Stage 30, Stage 29)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Submitting Stage 29 (MappedRDD[28] at subtract at UsersCollecting.scala:52), which has no missing parents
15/04/18 16:25:44 INFO storage.MemoryStore: ensureFreeSpace(2744) called with curMem=5712, maxMem=1016950947
15/04/18 16:25:44 INFO storage.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 2.7 KB, free 969.8 MB)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 29 (MappedRDD[28] at subtract at UsersCollecting.scala:52)
15/04/18 16:25:44 INFO scheduler.TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
15/04/18 16:25:44 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 16, localhost, PROCESS_LOCAL, 982 bytes)
15/04/18 16:25:44 INFO executor.Executor: Running task 0.0 in stage 29.0 (TID 16)
15/04/18 16:25:44 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:25:44 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:25:44 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Submitting Stage 30 (MappedRDD[29] at subtract at UsersCollecting.scala:52), which has no missing parents
15/04/18 16:25:44 INFO storage.MemoryStore: ensureFreeSpace(3600) called with curMem=8456, maxMem=1016950947
15/04/18 16:25:44 INFO storage.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 3.5 KB, free 969.8 MB)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Submitting 3 missing tasks from Stage 30 (MappedRDD[29] at subtract at UsersCollecting.scala:52)
15/04/18 16:25:44 INFO scheduler.TaskSchedulerImpl: Adding task set 30.0 with 3 tasks
15/04/18 16:25:44 INFO executor.Executor: Finished task 0.0 in stage 29.0 (TID 16). 1005 bytes result sent to driver
15/04/18 16:25:44 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 30.0 (TID 17, localhost, PROCESS_LOCAL, 1312 bytes)
15/04/18 16:25:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 16) in 71 ms on localhost (1/1)
15/04/18 16:25:44 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Stage 29 (subtract at UsersCollecting.scala:52) finished in 0,073 s
15/04/18 16:25:44 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/04/18 16:25:44 INFO scheduler.DAGScheduler: running: Set(Stage 30)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: waiting: Set(Stage 27)
15/04/18 16:25:44 INFO scheduler.DAGScheduler: failed: Set()
15/04/18 16:25:44 INFO scheduler.DAGScheduler: Missing parents for Stage 27: List(Stage 30)
15/04/18 16:25:44 INFO executor.Executor: Running task 0.0 in stage 30.0 (TID 17)
15/04/18 16:25:44 INFO executor.Executor: Finished task 0.0 in stage 30.0 (TID 17). 814 bytes result sent to driver
15/04/18 16:25:44 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 30.0 (TID 18, localhost, PROCESS_LOCAL, 1316 bytes)
15/04/18 16:25:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 30.0 (TID 17) in 9 ms on localhost (1/3)
15/04/18 16:25:44 INFO executor.Executor: Running task 1.0 in stage 30.0 (TID 18)
Downloading user 1
Downloading user 907
15/04/18 16:25:49 INFO executor.Executor: Finished task 1.0 in stage 30.0 (TID 18). 1005 bytes result sent to driver
15/04/18 16:25:49 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 30.0 (TID 19, localhost, PROCESS_LOCAL, 1389 bytes)
15/04/18 16:25:49 INFO executor.Executor: Running task 2.0 in stage 30.0 (TID 19)
15/04/18 16:25:49 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 30.0 (TID 18) in 4877 ms on localhost (2/3)
Downloading user 20720185
Downloading user 29825869
Downloading user 1666872
Downloading user 294029
Downloading user 1708231
Downloading user 961430
15/04/18 16:26:55 INFO spark.ContextCleaner: Cleaned shuffle 4
15/04/18 16:26:55 INFO spark.ContextCleaner: Cleaned shuffle 3
15/04/18 16:26:55 INFO spark.ContextCleaner: Cleaned shuffle 2
15/04/18 16:26:55 INFO spark.ContextCleaner: Cleaned shuffle 1
15/04/18 16:26:55 INFO spark.ContextCleaner: Cleaned shuffle 0
15/04/18 16:26:55 INFO storage.ShuffleBlockManager: Deleted all files for shuffle 4
15/04/18 16:26:55 INFO storage.ShuffleBlockManager: Deleted all files for shuffle 0
15/04/18 16:26:55 INFO storage.ShuffleBlockManager: Deleted all files for shuffle 1
Downloading user 2791
15/04/18 16:26:55 INFO storage.ShuffleBlockManager: Deleted all files for shuffle 2
15/04/18 16:26:55 INFO storage.ShuffleBlockManager: Deleted all files for shuffle 3
15/04/18 16:26:55 INFO storage.BlockManager: Removing broadcast 15
15/04/18 16:26:55 INFO storage.BlockManager: Removing block broadcast_15
15/04/18 16:26:55 INFO storage.MemoryStore: Block broadcast_15 of size 2744 dropped from memory (free 1016941635)
15/04/18 16:26:55 INFO spark.ContextCleaner: Cleaned broadcast 15
15/04/18 16:26:55 INFO storage.BlockManager: Removing broadcast 14
15/04/18 16:26:55 INFO storage.BlockManager: Removing block broadcast_14
15/04/18 16:26:55 INFO storage.MemoryStore: Block broadcast_14 of size 2536 dropped from memory (free 1016944171)
15/04/18 16:26:55 INFO spark.ContextCleaner: Cleaned broadcast 14
15/04/18 16:26:55 INFO storage.BlockManager: Removing broadcast 13
15/04/18 16:26:55 INFO storage.BlockManager: Removing block broadcast_13
15/04/18 16:26:55 INFO storage.MemoryStore: Block broadcast_13 of size 3176 dropped from memory (free 1016947347)
15/04/18 16:26:55 INFO spark.ContextCleaner: Cleaned broadcast 13
Downloading user 1824209
Downloading user 407032
15/04/18 16:27:09 INFO executor.Executor: Finished task 2.0 in stage 30.0 (TID 19). 1005 bytes result sent to driver
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Stage 30 (subtract at UsersCollecting.scala:52) finished in 84,952 s
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 30.0 (TID 19) in 80019 ms on localhost (3/3)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/04/18 16:27:09 INFO scheduler.DAGScheduler: running: Set()
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
15/04/18 16:27:09 INFO scheduler.DAGScheduler: waiting: Set(Stage 27)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: failed: Set()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Missing parents for Stage 27: List()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting Stage 27 (MappedRDD[31] at subtract at UsersCollecting.scala:52), which is now runnable
15/04/18 16:27:09 INFO storage.MemoryStore: ensureFreeSpace(2208) called with curMem=3600, maxMem=1016950947
15/04/18 16:27:09 INFO storage.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 2.2 KB, free 969.8 MB)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 27 (MappedRDD[31] at subtract at UsersCollecting.scala:52)
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 20, localhost, PROCESS_LOCAL, 1839 bytes)
15/04/18 16:27:09 INFO executor.Executor: Running task 0.0 in stage 27.0 (TID 20)
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 2 non-empty blocks out of 3 blocks
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:27:09 INFO executor.Executor: Finished task 0.0 in stage 27.0 (TID 20). 864 bytes result sent to driver
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 20) in 38 ms on localhost (1/1)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Stage 27 (count at UsersCollecting.scala:53) finished in 0,038 s
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
15/04/18 16:27:09 INFO spark.SparkContext: Job finished: count at UsersCollecting.scala:53, took 85.025515513 s
MLQ.size = 7692
15/04/18 16:27:09 INFO spark.SparkContext: Starting job: take at UsersCollecting.scala:55
15/04/18 16:27:09 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 141 bytes
15/04/18 16:27:09 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 141 bytes
15/04/18 16:27:09 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 154 bytes
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Got job 10 (take at UsersCollecting.scala:55) with 1 output partitions (allowLocal=true)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Final stage: Stage 31(take at UsersCollecting.scala:55)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 33, Stage 34)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Missing parents: List()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting Stage 31 (MappedRDD[31] at subtract at UsersCollecting.scala:52), which has no missing parents
15/04/18 16:27:09 INFO storage.MemoryStore: ensureFreeSpace(2232) called with curMem=5808, maxMem=1016950947
15/04/18 16:27:09 INFO storage.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 2.2 KB, free 969.8 MB)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 31 (MappedRDD[31] at subtract at UsersCollecting.scala:52)
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 21, localhost, PROCESS_LOCAL, 1839 bytes)
15/04/18 16:27:09 INFO executor.Executor: Running task 0.0 in stage 31.0 (TID 21)
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 2 non-empty blocks out of 3 blocks
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/04/18 16:27:09 INFO executor.Executor: Finished task 0.0 in stage 31.0 (TID 21). 929 bytes result sent to driver
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 21) in 19 ms on localhost (1/1)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Stage 31 (take at UsersCollecting.scala:55) finished in 0,019 s
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
15/04/18 16:27:09 INFO spark.SparkContext: Job finished: take at UsersCollecting.scala:55, took 0.026071726 s
15/04/18 16:27:09 INFO spark.SparkContext: Starting job: count at UsersCollecting.scala:56
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Got job 11 (count at UsersCollecting.scala:56) with 1 output partitions (allowLocal=false)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Final stage: Stage 35(count at UsersCollecting.scala:56)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Parents of final stage: List()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Missing parents: List()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting Stage 35 (ParallelCollectionRDD[32] at parallelize at UsersCollecting.scala:55), which has no missing parents
15/04/18 16:27:09 INFO storage.MemoryStore: ensureFreeSpace(1056) called with curMem=8040, maxMem=1016950947
15/04/18 16:27:09 INFO storage.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 1056.0 B, free 969.8 MB)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 35 (ParallelCollectionRDD[32] at parallelize at UsersCollecting.scala:55)
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 22, localhost, PROCESS_LOCAL, 1302 bytes)
15/04/18 16:27:09 INFO executor.Executor: Running task 0.0 in stage 35.0 (TID 22)
15/04/18 16:27:09 INFO executor.Executor: Finished task 0.0 in stage 35.0 (TID 22). 623 bytes result sent to driver
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Stage 35 (count at UsersCollecting.scala:56) finished in 0,004 s
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 22) in 4 ms on localhost (1/1)
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
15/04/18 16:27:09 INFO spark.SparkContext: Job finished: count at UsersCollecting.scala:56, took 0.00813081 s
LOI.size = 10
15/04/18 16:27:09 INFO spark.SparkContext: Starting job: count at UsersCollecting.scala:59
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Registering RDD 33 (subtract at UsersCollecting.scala:58)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Registering RDD 34 (subtract at UsersCollecting.scala:58)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Got job 12 (count at UsersCollecting.scala:59) with 1 output partitions (allowLocal=false)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Final stage: Stage 36(count at UsersCollecting.scala:59)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 40, Stage 41)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Missing parents: List(Stage 40, Stage 41)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting Stage 40 (MappedRDD[33] at subtract at UsersCollecting.scala:58), which has no missing parents
15/04/18 16:27:09 INFO storage.MemoryStore: ensureFreeSpace(2240) called with curMem=9096, maxMem=1016950947
15/04/18 16:27:09 INFO storage.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 2.2 KB, free 969.8 MB)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 40 (MappedRDD[33] at subtract at UsersCollecting.scala:58)
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 23, localhost, PROCESS_LOCAL, 1828 bytes)
15/04/18 16:27:09 INFO executor.Executor: Running task 0.0 in stage 40.0 (TID 23)
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting Stage 41 (MappedRDD[34] at subtract at UsersCollecting.scala:58), which has no missing parents
15/04/18 16:27:09 INFO storage.MemoryStore: ensureFreeSpace(2048) called with curMem=11336, maxMem=1016950947
15/04/18 16:27:09 INFO storage.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 2.0 KB, free 969.8 MB)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 41 (MappedRDD[34] at subtract at UsersCollecting.scala:58)
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 2 non-empty blocks out of 3 blocks
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/04/18 16:27:09 INFO executor.Executor: Finished task 0.0 in stage 40.0 (TID 23). 1005 bytes result sent to driver
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 24, localhost, PROCESS_LOCAL, 1291 bytes)
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 23) in 55 ms on localhost (1/1)
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Stage 40 (subtract at UsersCollecting.scala:58) finished in 0,057 s
15/04/18 16:27:09 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/04/18 16:27:09 INFO scheduler.DAGScheduler: running: Set(Stage 41)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: waiting: Set(Stage 36)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: failed: Set()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Missing parents for Stage 36: List(Stage 41)
15/04/18 16:27:09 INFO executor.Executor: Running task 0.0 in stage 41.0 (TID 24)
15/04/18 16:27:09 INFO executor.Executor: Finished task 0.0 in stage 41.0 (TID 24). 814 bytes result sent to driver
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 24) in 9 ms on localhost (1/1)
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Stage 41 (subtract at UsersCollecting.scala:58) finished in 0,057 s
15/04/18 16:27:09 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/04/18 16:27:09 INFO scheduler.DAGScheduler: running: Set()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: waiting: Set(Stage 36)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: failed: Set()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Missing parents for Stage 36: List()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting Stage 36 (MappedRDD[36] at subtract at UsersCollecting.scala:58), which is now runnable
15/04/18 16:27:09 INFO storage.MemoryStore: ensureFreeSpace(2208) called with curMem=13384, maxMem=1016950947
15/04/18 16:27:09 INFO storage.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 2.2 KB, free 969.8 MB)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 36 (MappedRDD[36] at subtract at UsersCollecting.scala:58)
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 25, localhost, PROCESS_LOCAL, 1839 bytes)
15/04/18 16:27:09 INFO executor.Executor: Running task 0.0 in stage 36.0 (TID 25)
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: maxBytesInFlight: 50331648, targetRequestSize: 10066329
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
15/04/18 16:27:09 INFO storage.BlockFetcherIterator$BasicBlockFetcherIterator: Started 0 remote fetches in 0 ms
MLQ.size = 7682
15/04/18 16:27:09 INFO executor.Executor: Finished task 0.0 in stage 36.0 (TID 25). 864 bytes result sent to driver
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 25) in 15 ms on localhost (1/1)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Stage 36 (count at UsersCollecting.scala:59) finished in 0,015 s
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
15/04/18 16:27:09 INFO spark.SparkContext: Job finished: count at UsersCollecting.scala:59, took 0.088920198 s
15/04/18 16:27:09 INFO spark.SparkContext: Starting job: foreach at UsersCollecting.scala:63
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Got job 13 (foreach at UsersCollecting.scala:63) with 1 output partitions (allowLocal=false)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Final stage: Stage 42(foreach at UsersCollecting.scala:63)
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Parents of final stage: List()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Missing parents: List()
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting Stage 42 (MappedRDD[20] at map at UsersCollecting.scala:45), which has no missing parents
15/04/18 16:27:09 INFO storage.MemoryStore: ensureFreeSpace(2088) called with curMem=15592, maxMem=1016950947
15/04/18 16:27:09 INFO storage.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 2.0 KB, free 969.8 MB)
Downloading user 907
15/04/18 16:27:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 42 (MappedRDD[20] at map at UsersCollecting.scala:45)
15/04/18 16:27:09 INFO scheduler.TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
15/04/18 16:27:09 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 26, localhost, PROCESS_LOCAL, 1291 bytes)
15/04/18 16:27:09 INFO executor.Executor: Running task 0.0 in stage 42.0 (TID 26)
Indexing user: 907
no data of type postwill be indexed: no data provided
Downloading user 20720185
Indexing user: 20720185
Downloading user 29825869
Indexing user: 29825869
Downloading user 1666872
Indexing user: 1666872
Downloading user 294029
Indexing user: 294029
no data of type postwill be indexed: no data provided
Downloading user 1708231
Indexing user: 1708231
Downloading user 961430
Indexing user: 961430
Downloading user 2791
Indexing user: 2791
no data of type postwill be indexed: no data provided
Downloading user 1824209
Indexing user: 1824209
Downloading user 407032
Indexing user: 407032
10 more users added to index
success!
15/04/18 16:27:56 INFO executor.Executor: Finished task 0.0 in stage 42.0 (TID 26). 826 bytes result sent to driver
15/04/18 16:27:56 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 26) in 47178 ms on localhost (1/1)
15/04/18 16:27:56 INFO scheduler.DAGScheduler: Stage 42 (foreach at UsersCollecting.scala:63) finished in 47,179 s
15/04/18 16:27:56 INFO spark.SparkContext: Job finished: foreach at UsersCollecting.scala:63, took 47.285794986 s
15/04/18 16:27:56 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
